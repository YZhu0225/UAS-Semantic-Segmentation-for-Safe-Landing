{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMdigbwFmB7B",
        "outputId": "cf5aa84b-d795-46ad-9658-cfc992baa391"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Apr 13 22:00:12 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    23W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCoTx_6LmHpU",
        "outputId": "9baf3bc2-47b5-47c7-d07f-5814eff97d53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Tesla V100-SXM2-16GB for PyTorch\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")          # a CUDA device object\n",
        "    print(f\"Using {torch.cuda.get_device_name(0)} for PyTorch\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"No GPU found, using CPU instead\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBYpboQJmD69",
        "outputId": "f768766e-c8c9-489a-e61d-fcbbec076318"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:05<00:00, 29485766.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/50], Train Loss: 2.0561, Train Acc: 0.2768, Test Loss: 1.5767, Test Acc: 0.4235\n",
            "Epoch [2/50], Train Loss: 1.6875, Train Acc: 0.3845, Test Loss: 1.4516, Test Acc: 0.4684\n",
            "Epoch [3/50], Train Loss: 1.4708, Train Acc: 0.4725, Test Loss: 1.1510, Test Acc: 0.5848\n",
            "Epoch [4/50], Train Loss: 1.3050, Train Acc: 0.5351, Test Loss: 1.0044, Test Acc: 0.6425\n",
            "Epoch [5/50], Train Loss: 1.1578, Train Acc: 0.5903, Test Loss: 0.8405, Test Acc: 0.7069\n",
            "Epoch [6/50], Train Loss: 1.0585, Train Acc: 0.6287, Test Loss: 0.7945, Test Acc: 0.7215\n",
            "Epoch [7/50], Train Loss: 0.9693, Train Acc: 0.6621, Test Loss: 0.7385, Test Acc: 0.7507\n",
            "Epoch [8/50], Train Loss: 0.9215, Train Acc: 0.6785, Test Loss: 0.6633, Test Acc: 0.7707\n",
            "Epoch [9/50], Train Loss: 0.8802, Train Acc: 0.6943, Test Loss: 0.6083, Test Acc: 0.7893\n",
            "Epoch [10/50], Train Loss: 0.8430, Train Acc: 0.7035, Test Loss: 0.5190, Test Acc: 0.8202\n",
            "Epoch [11/50], Train Loss: 0.8137, Train Acc: 0.7158, Test Loss: 0.5464, Test Acc: 0.8119\n",
            "Epoch [12/50], Train Loss: 0.7872, Train Acc: 0.7260, Test Loss: 0.5225, Test Acc: 0.8205\n",
            "Epoch [13/50], Train Loss: 0.7785, Train Acc: 0.7286, Test Loss: 0.4731, Test Acc: 0.8425\n",
            "Epoch [14/50], Train Loss: 0.7483, Train Acc: 0.7397, Test Loss: 0.4775, Test Acc: 0.8355\n",
            "Epoch [15/50], Train Loss: 0.7337, Train Acc: 0.7436, Test Loss: 0.4201, Test Acc: 0.8568\n",
            "Epoch [16/50], Train Loss: 0.7150, Train Acc: 0.7522, Test Loss: 0.4832, Test Acc: 0.8368\n",
            "Epoch [17/50], Train Loss: 0.6989, Train Acc: 0.7571, Test Loss: 0.4406, Test Acc: 0.8474\n",
            "Epoch [18/50], Train Loss: 0.6931, Train Acc: 0.7586, Test Loss: 0.4347, Test Acc: 0.8511\n",
            "Epoch [19/50], Train Loss: 0.6808, Train Acc: 0.7634, Test Loss: 0.4255, Test Acc: 0.8580\n",
            "Epoch [20/50], Train Loss: 0.6737, Train Acc: 0.7687, Test Loss: 0.4742, Test Acc: 0.8382\n",
            "Epoch [21/50], Train Loss: 0.6671, Train Acc: 0.7690, Test Loss: 0.4039, Test Acc: 0.8594\n",
            "Epoch [22/50], Train Loss: 0.6541, Train Acc: 0.7731, Test Loss: 0.4194, Test Acc: 0.8566\n",
            "Epoch [23/50], Train Loss: 0.6526, Train Acc: 0.7712, Test Loss: 0.4152, Test Acc: 0.8608\n",
            "Epoch [24/50], Train Loss: 0.6488, Train Acc: 0.7748, Test Loss: 0.3909, Test Acc: 0.8707\n",
            "Epoch [25/50], Train Loss: 0.6350, Train Acc: 0.7787, Test Loss: 0.3855, Test Acc: 0.8687\n",
            "Epoch [26/50], Train Loss: 0.6350, Train Acc: 0.7804, Test Loss: 0.3605, Test Acc: 0.8778\n",
            "Epoch [27/50], Train Loss: 0.6185, Train Acc: 0.7837, Test Loss: 0.4108, Test Acc: 0.8612\n",
            "Epoch [28/50], Train Loss: 0.6237, Train Acc: 0.7842, Test Loss: 0.3473, Test Acc: 0.8820\n",
            "Epoch [29/50], Train Loss: 0.6128, Train Acc: 0.7866, Test Loss: 0.4135, Test Acc: 0.8599\n",
            "Epoch [30/50], Train Loss: 0.6112, Train Acc: 0.7884, Test Loss: 0.3885, Test Acc: 0.8703\n",
            "Epoch [31/50], Train Loss: 0.6017, Train Acc: 0.7901, Test Loss: 0.3855, Test Acc: 0.8663\n",
            "Epoch [32/50], Train Loss: 0.6050, Train Acc: 0.7899, Test Loss: 0.4060, Test Acc: 0.8613\n",
            "Epoch [33/50], Train Loss: 0.5973, Train Acc: 0.7919, Test Loss: 0.3304, Test Acc: 0.8857\n",
            "Epoch [34/50], Train Loss: 0.5914, Train Acc: 0.7929, Test Loss: 0.3419, Test Acc: 0.8825\n",
            "Epoch [35/50], Train Loss: 0.5926, Train Acc: 0.7963, Test Loss: 0.3868, Test Acc: 0.8667\n",
            "Epoch [36/50], Train Loss: 0.5928, Train Acc: 0.7968, Test Loss: 0.3793, Test Acc: 0.8699\n",
            "Epoch [37/50], Train Loss: 0.5906, Train Acc: 0.7960, Test Loss: 0.3414, Test Acc: 0.8825\n",
            "Epoch [38/50], Train Loss: 0.5805, Train Acc: 0.7999, Test Loss: 0.3775, Test Acc: 0.8728\n",
            "Epoch [39/50], Train Loss: 0.5849, Train Acc: 0.7974, Test Loss: 0.3358, Test Acc: 0.8859\n",
            "Epoch [40/50], Train Loss: 0.5805, Train Acc: 0.7986, Test Loss: 0.3766, Test Acc: 0.8706\n",
            "Epoch [41/50], Train Loss: 0.5757, Train Acc: 0.8016, Test Loss: 0.5072, Test Acc: 0.8407\n",
            "Epoch [42/50], Train Loss: 0.5754, Train Acc: 0.7997, Test Loss: 0.3540, Test Acc: 0.8818\n",
            "Epoch [43/50], Train Loss: 0.5764, Train Acc: 0.8022, Test Loss: 0.3761, Test Acc: 0.8731\n",
            "Epoch [44/50], Train Loss: 0.5639, Train Acc: 0.8056, Test Loss: 0.3340, Test Acc: 0.8879\n",
            "Epoch [45/50], Train Loss: 0.5710, Train Acc: 0.8029, Test Loss: 0.3352, Test Acc: 0.8896\n",
            "Epoch [46/50], Train Loss: 0.5695, Train Acc: 0.8039, Test Loss: 0.3323, Test Acc: 0.8859\n",
            "Epoch [47/50], Train Loss: 0.5637, Train Acc: 0.8042, Test Loss: 0.3485, Test Acc: 0.8823\n",
            "Epoch [48/50], Train Loss: 0.5604, Train Acc: 0.8059, Test Loss: 0.3273, Test Acc: 0.8891\n",
            "Epoch [49/50], Train Loss: 0.5519, Train Acc: 0.8106, Test Loss: 0.3200, Test Acc: 0.8910\n",
            "Epoch [50/50], Train Loss: 0.5588, Train Acc: 0.8078, Test Loss: 0.3620, Test Acc: 0.8789\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "\n",
        "# Set device to use\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define data transformations\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "# Load CIFAR10 dataset\n",
        "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "# Define data loaders\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=4)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=4)\n",
        "\n",
        "# Define ResNet-18 model\n",
        "model = models.resnet18(pretrained=False).to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    # Train the model\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    train_correct = 0\n",
        "    for images, labels in trainloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * images.size(0)\n",
        "        train_correct += (outputs.argmax(dim=1) == labels).sum().item()\n",
        "\n",
        "    # Test the model\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    test_correct = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            test_loss += loss.item() * images.size(0)\n",
        "            test_correct += (outputs.argmax(dim=1) == labels).sum().item()\n",
        "\n",
        "    # Print results for this epoch\n",
        "    train_loss /= len(trainset)\n",
        "    train_acc = train_correct / len(trainset)\n",
        "    test_loss /= len(testset)\n",
        "    test_acc = test_correct / len(testset)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')\n",
        "\n",
        "# Save the trained model\n",
        "# torch.save(model.state_dict(), 'resnet50_imagenet.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fN2WFDUmQGA"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yaUXLcMCnmx3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nNLHQV_BePV"
      },
      "source": [
        "100 epochs, larger batch size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEy64eEaBhEc",
        "outputId": "609b7af7-2bf6-4509-f019-d46418192a64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch [1/100], Train Loss: 2.3427, Train Acc: 0.2294, Test Loss: 1.7524, Test Acc: 0.3252\n",
            "Epoch [2/100], Train Loss: 1.7828, Train Acc: 0.3384, Test Loss: 1.5765, Test Acc: 0.4192\n",
            "Epoch [3/100], Train Loss: 1.6583, Train Acc: 0.3947, Test Loss: 1.4240, Test Acc: 0.4798\n",
            "Epoch [4/100], Train Loss: 1.5200, Train Acc: 0.4510, Test Loss: 1.2906, Test Acc: 0.5320\n",
            "Epoch [5/100], Train Loss: 1.3762, Train Acc: 0.5071, Test Loss: 1.0479, Test Acc: 0.6318\n",
            "Epoch [6/100], Train Loss: 1.2633, Train Acc: 0.5494, Test Loss: 1.0286, Test Acc: 0.6356\n",
            "Epoch [7/100], Train Loss: 1.1657, Train Acc: 0.5850, Test Loss: 0.9248, Test Acc: 0.6784\n",
            "Epoch [8/100], Train Loss: 1.0743, Train Acc: 0.6212, Test Loss: 0.7451, Test Acc: 0.7428\n",
            "Epoch [9/100], Train Loss: 1.0018, Train Acc: 0.6464, Test Loss: 0.7659, Test Acc: 0.7312\n",
            "Epoch [10/100], Train Loss: 0.9447, Train Acc: 0.6689, Test Loss: 0.7496, Test Acc: 0.7465\n",
            "Epoch [11/100], Train Loss: 0.8937, Train Acc: 0.6867, Test Loss: 0.6122, Test Acc: 0.7877\n",
            "Epoch [12/100], Train Loss: 0.8502, Train Acc: 0.7021, Test Loss: 0.6269, Test Acc: 0.7898\n",
            "Epoch [13/100], Train Loss: 0.8153, Train Acc: 0.7143, Test Loss: 0.5666, Test Acc: 0.8063\n",
            "Epoch [14/100], Train Loss: 0.7804, Train Acc: 0.7286, Test Loss: 0.5379, Test Acc: 0.8148\n",
            "Epoch [15/100], Train Loss: 0.7584, Train Acc: 0.7348, Test Loss: 0.5505, Test Acc: 0.8115\n",
            "Epoch [16/100], Train Loss: 0.7248, Train Acc: 0.7481, Test Loss: 0.4954, Test Acc: 0.8295\n",
            "Epoch [17/100], Train Loss: 0.7106, Train Acc: 0.7513, Test Loss: 0.4566, Test Acc: 0.8465\n",
            "Epoch [18/100], Train Loss: 0.6940, Train Acc: 0.7563, Test Loss: 0.4711, Test Acc: 0.8414\n",
            "Epoch [19/100], Train Loss: 0.6803, Train Acc: 0.7624, Test Loss: 0.4471, Test Acc: 0.8474\n",
            "Epoch [20/100], Train Loss: 0.6527, Train Acc: 0.7738, Test Loss: 0.4983, Test Acc: 0.8305\n",
            "Epoch [21/100], Train Loss: 0.6546, Train Acc: 0.7728, Test Loss: 0.4473, Test Acc: 0.8498\n",
            "Epoch [22/100], Train Loss: 0.6330, Train Acc: 0.7780, Test Loss: 0.3887, Test Acc: 0.8646\n",
            "Epoch [23/100], Train Loss: 0.6217, Train Acc: 0.7854, Test Loss: 0.4279, Test Acc: 0.8480\n",
            "Epoch [24/100], Train Loss: 0.6153, Train Acc: 0.7857, Test Loss: 0.4039, Test Acc: 0.8614\n",
            "Epoch [25/100], Train Loss: 0.6023, Train Acc: 0.7881, Test Loss: 0.4014, Test Acc: 0.8659\n",
            "Epoch [26/100], Train Loss: 0.5954, Train Acc: 0.7912, Test Loss: 0.3723, Test Acc: 0.8724\n",
            "Epoch [27/100], Train Loss: 0.5804, Train Acc: 0.7977, Test Loss: 0.3725, Test Acc: 0.8710\n",
            "Epoch [28/100], Train Loss: 0.5775, Train Acc: 0.7969, Test Loss: 0.3665, Test Acc: 0.8743\n",
            "Epoch [29/100], Train Loss: 0.5702, Train Acc: 0.8030, Test Loss: 0.4131, Test Acc: 0.8663\n",
            "Epoch [30/100], Train Loss: 0.5678, Train Acc: 0.8017, Test Loss: 0.3550, Test Acc: 0.8804\n",
            "Epoch [31/100], Train Loss: 0.5547, Train Acc: 0.8081, Test Loss: 0.3835, Test Acc: 0.8724\n",
            "Epoch [32/100], Train Loss: 0.5509, Train Acc: 0.8085, Test Loss: 0.3861, Test Acc: 0.8740\n",
            "Epoch [33/100], Train Loss: 0.5423, Train Acc: 0.8120, Test Loss: 0.3580, Test Acc: 0.8820\n",
            "Epoch [34/100], Train Loss: 0.5391, Train Acc: 0.8098, Test Loss: 0.4008, Test Acc: 0.8693\n",
            "Epoch [35/100], Train Loss: 0.5354, Train Acc: 0.8138, Test Loss: 0.3792, Test Acc: 0.8709\n",
            "Epoch [36/100], Train Loss: 0.5325, Train Acc: 0.8154, Test Loss: 0.3263, Test Acc: 0.8884\n",
            "Epoch [37/100], Train Loss: 0.5181, Train Acc: 0.8205, Test Loss: 0.3466, Test Acc: 0.8877\n",
            "Epoch [38/100], Train Loss: 0.5226, Train Acc: 0.8179, Test Loss: 0.3341, Test Acc: 0.8886\n",
            "Epoch [39/100], Train Loss: 0.5191, Train Acc: 0.8192, Test Loss: 0.3820, Test Acc: 0.8686\n",
            "Epoch [40/100], Train Loss: 0.5160, Train Acc: 0.8218, Test Loss: 0.3208, Test Acc: 0.8894\n",
            "Epoch [41/100], Train Loss: 0.5138, Train Acc: 0.8211, Test Loss: 0.3311, Test Acc: 0.8914\n",
            "Epoch [42/100], Train Loss: 0.5032, Train Acc: 0.8272, Test Loss: 0.3442, Test Acc: 0.8848\n",
            "Epoch [43/100], Train Loss: 0.5029, Train Acc: 0.8253, Test Loss: 0.3221, Test Acc: 0.8923\n",
            "Epoch [44/100], Train Loss: 0.5028, Train Acc: 0.8255, Test Loss: 0.3122, Test Acc: 0.8955\n",
            "Epoch [45/100], Train Loss: 0.4990, Train Acc: 0.8253, Test Loss: 0.3586, Test Acc: 0.8792\n",
            "Epoch [46/100], Train Loss: 0.4919, Train Acc: 0.8276, Test Loss: 0.3285, Test Acc: 0.8903\n",
            "Epoch [47/100], Train Loss: 0.4809, Train Acc: 0.8313, Test Loss: 0.3697, Test Acc: 0.8813\n",
            "Epoch [48/100], Train Loss: 0.4933, Train Acc: 0.8284, Test Loss: 0.3797, Test Acc: 0.8719\n",
            "Epoch [49/100], Train Loss: 0.4813, Train Acc: 0.8319, Test Loss: 0.4140, Test Acc: 0.8709\n",
            "Epoch [50/100], Train Loss: 0.4899, Train Acc: 0.8298, Test Loss: 0.3338, Test Acc: 0.8874\n",
            "Epoch [51/100], Train Loss: 0.4797, Train Acc: 0.8343, Test Loss: 0.3206, Test Acc: 0.8942\n",
            "Epoch [52/100], Train Loss: 0.4764, Train Acc: 0.8355, Test Loss: 0.2885, Test Acc: 0.9040\n",
            "Epoch [53/100], Train Loss: 0.4747, Train Acc: 0.8357, Test Loss: 0.3090, Test Acc: 0.8937\n",
            "Epoch [54/100], Train Loss: 0.4717, Train Acc: 0.8355, Test Loss: 0.3250, Test Acc: 0.8916\n",
            "Epoch [55/100], Train Loss: 0.4662, Train Acc: 0.8393, Test Loss: 0.3341, Test Acc: 0.8874\n",
            "Epoch [56/100], Train Loss: 0.4622, Train Acc: 0.8384, Test Loss: 0.3598, Test Acc: 0.8834\n",
            "Epoch [57/100], Train Loss: 0.4670, Train Acc: 0.8372, Test Loss: 0.2935, Test Acc: 0.9021\n",
            "Epoch [58/100], Train Loss: 0.4629, Train Acc: 0.8381, Test Loss: 0.3528, Test Acc: 0.8838\n",
            "Epoch [59/100], Train Loss: 0.4581, Train Acc: 0.8423, Test Loss: 0.3313, Test Acc: 0.8914\n",
            "Epoch [60/100], Train Loss: 0.4606, Train Acc: 0.8396, Test Loss: 0.3410, Test Acc: 0.8923\n",
            "Epoch [61/100], Train Loss: 0.4579, Train Acc: 0.8407, Test Loss: 0.2921, Test Acc: 0.9018\n",
            "Epoch [62/100], Train Loss: 0.4564, Train Acc: 0.8419, Test Loss: 0.3274, Test Acc: 0.8895\n",
            "Epoch [63/100], Train Loss: 0.4600, Train Acc: 0.8408, Test Loss: 0.2898, Test Acc: 0.9008\n",
            "Epoch [64/100], Train Loss: 0.4491, Train Acc: 0.8426, Test Loss: 0.3411, Test Acc: 0.8885\n",
            "Epoch [65/100], Train Loss: 0.4396, Train Acc: 0.8471, Test Loss: 0.3054, Test Acc: 0.9001\n",
            "Epoch [66/100], Train Loss: 0.4452, Train Acc: 0.8464, Test Loss: 0.3426, Test Acc: 0.8896\n",
            "Epoch [67/100], Train Loss: 0.4443, Train Acc: 0.8453, Test Loss: 0.2876, Test Acc: 0.9008\n",
            "Epoch [68/100], Train Loss: 0.4496, Train Acc: 0.8446, Test Loss: 0.3324, Test Acc: 0.8941\n",
            "Epoch [69/100], Train Loss: 0.4470, Train Acc: 0.8453, Test Loss: 0.2744, Test Acc: 0.9086\n",
            "Epoch [70/100], Train Loss: 0.4416, Train Acc: 0.8466, Test Loss: 0.3161, Test Acc: 0.9025\n",
            "Epoch [71/100], Train Loss: 0.4457, Train Acc: 0.8455, Test Loss: 0.2937, Test Acc: 0.9036\n",
            "Epoch [72/100], Train Loss: 0.4390, Train Acc: 0.8467, Test Loss: 0.3102, Test Acc: 0.8971\n",
            "Epoch [73/100], Train Loss: 0.4388, Train Acc: 0.8469, Test Loss: 0.3008, Test Acc: 0.9050\n",
            "Epoch [74/100], Train Loss: 0.4395, Train Acc: 0.8477, Test Loss: 0.3264, Test Acc: 0.8926\n",
            "Epoch [75/100], Train Loss: 0.4367, Train Acc: 0.8477, Test Loss: 0.3217, Test Acc: 0.8979\n",
            "Epoch [76/100], Train Loss: 0.4391, Train Acc: 0.8457, Test Loss: 0.2788, Test Acc: 0.9057\n",
            "Epoch [77/100], Train Loss: 0.4413, Train Acc: 0.8472, Test Loss: 0.2902, Test Acc: 0.9048\n",
            "Epoch [78/100], Train Loss: 0.4375, Train Acc: 0.8496, Test Loss: 0.2799, Test Acc: 0.9061\n",
            "Epoch [79/100], Train Loss: 0.4321, Train Acc: 0.8509, Test Loss: 0.3408, Test Acc: 0.8933\n",
            "Epoch [80/100], Train Loss: 0.4374, Train Acc: 0.8477, Test Loss: 0.3086, Test Acc: 0.8987\n",
            "Epoch [81/100], Train Loss: 0.4330, Train Acc: 0.8483, Test Loss: 0.3290, Test Acc: 0.8927\n",
            "Epoch [82/100], Train Loss: 0.4363, Train Acc: 0.8483, Test Loss: 0.2742, Test Acc: 0.9098\n",
            "Epoch [83/100], Train Loss: 0.4283, Train Acc: 0.8517, Test Loss: 0.2679, Test Acc: 0.9118\n",
            "Epoch [84/100], Train Loss: 0.4310, Train Acc: 0.8504, Test Loss: 0.2945, Test Acc: 0.8993\n",
            "Epoch [85/100], Train Loss: 0.4272, Train Acc: 0.8522, Test Loss: 0.2777, Test Acc: 0.9116\n",
            "Epoch [86/100], Train Loss: 0.4296, Train Acc: 0.8493, Test Loss: 0.2937, Test Acc: 0.9040\n",
            "Epoch [87/100], Train Loss: 0.4285, Train Acc: 0.8519, Test Loss: 0.3014, Test Acc: 0.9018\n",
            "Epoch [88/100], Train Loss: 0.4343, Train Acc: 0.8487, Test Loss: 0.2842, Test Acc: 0.9099\n",
            "Epoch [89/100], Train Loss: 0.4278, Train Acc: 0.8508, Test Loss: 0.3120, Test Acc: 0.8951\n",
            "Epoch [90/100], Train Loss: 0.4252, Train Acc: 0.8517, Test Loss: 0.2846, Test Acc: 0.9066\n",
            "Epoch [91/100], Train Loss: 0.4251, Train Acc: 0.8527, Test Loss: 0.2648, Test Acc: 0.9119\n",
            "Epoch [92/100], Train Loss: 0.4193, Train Acc: 0.8532, Test Loss: 0.2983, Test Acc: 0.9042\n",
            "Epoch [93/100], Train Loss: 0.4197, Train Acc: 0.8548, Test Loss: 0.2846, Test Acc: 0.9046\n",
            "Epoch [94/100], Train Loss: 0.4182, Train Acc: 0.8559, Test Loss: 0.3125, Test Acc: 0.8968\n",
            "Epoch [95/100], Train Loss: 0.4252, Train Acc: 0.8517, Test Loss: 0.2921, Test Acc: 0.9050\n",
            "Epoch [96/100], Train Loss: 0.4249, Train Acc: 0.8517, Test Loss: 0.3538, Test Acc: 0.8904\n",
            "Epoch [97/100], Train Loss: 0.4232, Train Acc: 0.8522, Test Loss: 0.3145, Test Acc: 0.8975\n",
            "Epoch [98/100], Train Loss: 0.4154, Train Acc: 0.8550, Test Loss: 0.2877, Test Acc: 0.9073\n",
            "Epoch [99/100], Train Loss: 0.4229, Train Acc: 0.8525, Test Loss: 0.3519, Test Acc: 0.8899\n",
            "Epoch [100/100], Train Loss: 0.4165, Train Acc: 0.8568, Test Loss: 0.3414, Test Acc: 0.8959\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "\n",
        "# Set device to use\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define data transformations\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "# Load CIFAR10 dataset\n",
        "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "# Define data loaders\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=4)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=4)\n",
        "\n",
        "# Define ResNet-18 model\n",
        "model = models.resnet18(pretrained=False).to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    # Train the model\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    train_correct = 0\n",
        "    for images, labels in trainloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * images.size(0)\n",
        "        train_correct += (outputs.argmax(dim=1) == labels).sum().item()\n",
        "\n",
        "    # Test the model\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    test_correct = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            test_loss += loss.item() * images.size(0)\n",
        "            test_correct += (outputs.argmax(dim=1) == labels).sum().item()\n",
        "\n",
        "    # Print results for this epoch\n",
        "    train_loss /= len(trainset)\n",
        "    train_acc = train_correct / len(trainset)\n",
        "    test_loss /= len(testset)\n",
        "    test_acc = test_correct / len(testset)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')\n",
        "\n",
        "# Save the trained model\n",
        "# torch.save(model.state_dict(), 'resnet50_imagenet.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y--z6SVnEOxm"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
